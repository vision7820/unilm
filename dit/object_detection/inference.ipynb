{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from ditod import add_vit_config\n",
    "\n",
    "import torch\n",
    "\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import ColorMode, Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.engine import DefaultPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = \"publaynet_configs/maskrcnn/maskrcnn_dit_base.yaml\"\n",
    "opts = ['MODEL.WEIGHTS', 'https://layoutlm.blob.core.windows.net/dit/dit-fts/publaynet_dit-b_mrcnn.pth']\n",
    "image = \"test.jpeg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def predict(image):\n",
    "    # Step 1: instantiate config\n",
    "    cfg = get_cfg()\n",
    "    add_vit_config(cfg)\n",
    "    cfg.merge_from_file(config)\n",
    "\n",
    "    # Step 2: add model weights URL to config\n",
    "    cfg.merge_from_list(opts)\n",
    "\n",
    "    # Step 3: set device\n",
    "    device = \"cpu\"\n",
    "    cfg.MODEL.DEVICE = device\n",
    "\n",
    "    # Step 4: define model\n",
    "    predictor = DefaultPredictor(cfg)\n",
    "    # Step 5: run inference\n",
    "    img = cv2.imread(image)\n",
    "\n",
    "    md = MetadataCatalog.get(cfg.DATASETS.TEST[0])\n",
    "    if cfg.DATASETS.TEST[0]=='icdar2019_test':\n",
    "        md.set(thing_classes=[\"table\"])\n",
    "    else:\n",
    "        md.set(thing_classes=[\"text\",\"title\",\"list\",\"table\",\"figure\"])\n",
    "        \n",
    "    output = predictor(img)[\"instances\"]\n",
    "        \n",
    "    v = Visualizer(img[:, :, ::-1],\n",
    "                md,\n",
    "                scale=1.0,\n",
    "                instance_mode=ColorMode.SEGMENTATION)\n",
    "    result = v.draw_instance_predictions(output.to(\"cpu\"))\n",
    "    result_image = result.get_image()[:, :, ::-1]\n",
    "    \n",
    "    return img, result_image, output.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, result_img, output = predict(\"test.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(\"out.jpg\", result_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instances(num_instances=12, image_height=792, image_width=601, fields=[pred_boxes: Boxes(tensor([[308.5944, 387.7310, 548.3193, 549.9556],\n",
      "        [ 50.5924, 636.3325, 290.5307, 742.6828],\n",
      "        [ 50.7837, 488.1688, 290.5877, 639.7428],\n",
      "        [308.5706, 545.3228, 548.6179, 743.0535],\n",
      "        [ 50.4487, 339.1625, 290.8231, 444.3589],\n",
      "        [308.0231, 316.4781, 549.6226, 353.0624],\n",
      "        [ 50.5810, 316.2806, 291.1252, 341.4015],\n",
      "        [ 50.5080,  71.7657, 549.5928,  94.8253],\n",
      "        [ 51.0327, 442.5561, 290.5040, 490.1516],\n",
      "        [308.2527, 367.4326, 379.5883, 380.3791],\n",
      "        [ 51.0582, 101.4618, 549.3663, 278.4562],\n",
      "        [ 51.7424, 279.6494, 133.8992, 289.6211]])), scores: tensor([1.0000, 0.9999, 0.9999, 0.9999, 0.9998, 0.9997, 0.9997, 0.9995, 0.9994,\n",
      "        0.9993, 0.9990, 0.9979]), pred_classes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 0]), pred_masks: tensor([[[False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         ...,\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False]],\n",
      "\n",
      "        [[False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         ...,\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False]],\n",
      "\n",
      "        [[False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         ...,\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         ...,\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False]],\n",
      "\n",
      "        [[False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         ...,\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False]],\n",
      "\n",
      "        [[False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         ...,\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False]]])])\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_index(instance):\n",
    "    bbox = instance.pred_boxes.tensor\n",
    "    sorting = sorted(range(bbox.size()[0]), key=lambda k: bbox[k][1].numpy())\n",
    "    return sorting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_tensor(tensor, sort_mask):\n",
    "    return tensor[sort_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort(instance):\n",
    "    sort_mask = sort_index(instance)\n",
    "    # sort pred_boxes\n",
    "    instance.pred_boxes.tensor = sort_tensor(instance.pred_boxes.tensor, sort_mask)\n",
    "    # sort score\n",
    "    instance.scores = sort_tensor(instance.scores, sort_mask)\n",
    "    # sort pred_classes\n",
    "    instance.pred_classes = sort_tensor(instance.pred_classes, sort_mask)\n",
    "    # sort pred_masks\n",
    "    instance.pred_masks = sort_tensor(instance.pred_masks, sort_mask)\n",
    "    return instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_remove_mask(instance, conf):\n",
    "    scores = instance.scores\n",
    "    out_mask = []\n",
    "    for idx,score in enumerate(scores):\n",
    "        if score >= conf:\n",
    "            out_mask.append(idx)\n",
    "    return out_mask\n",
    "\n",
    "def filter_tensor(tensor, mask):\n",
    "    return tensor[mask]\n",
    "\n",
    "def remove_box_lower_than(instance, conf):\n",
    "    mask = get_remove_mask(instance, conf)\n",
    "    # sort pred_boxes\n",
    "    instance.pred_boxes.tensor = filter_tensor(instance.pred_boxes.tensor, mask)\n",
    "    # sort score\n",
    "    instance.scores = filter_tensor(instance.scores, mask)\n",
    "    # sort pred_classes\n",
    "    instance.pred_classes = filter_tensor(instance.pred_classes, mask)\n",
    "    # sort pred_masks\n",
    "    instance.pred_masks = filter_tensor(instance.pred_masks, mask)\n",
    "\n",
    "    return instance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(212, 290, 3)\n",
      "(156, 290, 3)\n",
      "(201, 290, 3)\n",
      "(248, 290, 3)\n",
      "(155, 290, 3)\n",
      "(87, 291, 3)\n",
      "(75, 291, 3)\n",
      "(73, 549, 3)\n",
      "(98, 289, 3)\n",
      "(63, 121, 3)\n",
      "(227, 548, 3)\n",
      "(60, 132, 3)\n"
     ]
    }
   ],
   "source": [
    "def add_padding(input_img, padding, color):\n",
    "    old_image_height, old_image_width, channels = input_img.shape\n",
    "\n",
    "    # create new image of desired size and color (blue) for padding\n",
    "    new_image_width = old_image_width + 2 * padding\n",
    "    new_image_height = old_image_height + 2 * padding\n",
    "    result = np.full((new_image_height,new_image_width, channels), color, dtype=np.uint8)\n",
    "    print(result.shape)\n",
    "\n",
    "    # compute center offset\n",
    "    x_center = (new_image_width - old_image_width) // 2\n",
    "    y_center = (new_image_height - old_image_height) // 2\n",
    "\n",
    "    # copy img image into center of result image\n",
    "    result[y_center:y_center+old_image_height,\n",
    "           x_center:x_center+old_image_width] = input_img\n",
    "    return result\n",
    "\n",
    "def crop_and_save_image(input_img, bbox, filename, padding=25, color=(255,255,255)):\n",
    "    height, width, channels = input_img.shape\n",
    "    x1 = int(bbox[0])\n",
    "    x2 = int(bbox[2])\n",
    "    y1 = int(bbox[1])\n",
    "    y2 = int(bbox[3])\n",
    "    cropped_image = input_img[y1:y2, x1:x2]\n",
    "    padded_image = add_padding(cropped_image, padding, color)\n",
    "    cv2.imwrite(filename, padded_image)\n",
    "\n",
    "out_folder = \"out\"\n",
    "img = cv2.imread(image)\n",
    "\n",
    "\n",
    "for idx, box in enumerate(output.pred_boxes.tensor):\n",
    "    crop_and_save_image(img, box, os.path.join(out_folder, str(idx) + \".jpg\"), 25)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}