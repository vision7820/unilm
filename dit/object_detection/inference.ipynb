{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pytesseract\n",
    "\n",
    "from ditod import add_vit_config\n",
    "\n",
    "import torch\n",
    "\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import ColorMode, Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.engine import DefaultPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = \"publaynet_configs/maskrcnn/maskrcnn_dit_base.yaml\"\n",
    "opts = ['MODEL.WEIGHTS', 'https://layoutlm.blob.core.windows.net/dit/dit-fts/publaynet_dit-b_mrcnn.pth']\n",
    "image = \"5.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def predict(image):\n",
    "    # Step 1: instantiate config\n",
    "    cfg = get_cfg()\n",
    "    add_vit_config(cfg)\n",
    "    cfg.merge_from_file(config)\n",
    "\n",
    "    # Step 2: add model weights URL to config\n",
    "    cfg.merge_from_list(opts)\n",
    "\n",
    "    # Step 3: set device\n",
    "    device = \"cpu\"\n",
    "    cfg.MODEL.DEVICE = device\n",
    "\n",
    "    # Step 4: define model\n",
    "    predictor = DefaultPredictor(cfg)\n",
    "    # Step 5: run inference\n",
    "    img = cv2.imread(image)\n",
    "\n",
    "    md = MetadataCatalog.get(cfg.DATASETS.TEST[0])\n",
    "    if cfg.DATASETS.TEST[0]=='icdar2019_test':\n",
    "        md.set(thing_classes=[\"table\"])\n",
    "    else:\n",
    "        md.set(thing_classes=[\"text\",\"title\",\"list\",\"table\",\"figure\"])\n",
    "        \n",
    "    output = predictor(img)[\"instances\"]\n",
    "        \n",
    "    v = Visualizer(img[:, :, ::-1],\n",
    "                md,\n",
    "                scale=1.0,\n",
    "                instance_mode=ColorMode.SEGMENTATION)\n",
    "    result = v.draw_instance_predictions(output.to(\"cpu\"))\n",
    "    result_image = result.get_image()[:, :, ::-1]\n",
    "    \n",
    "    return img, result_image, output.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hansheng/Desktop/unilm/dit/venv/lib/python3.7/site-packages/torch/nn/functional.py:3613: UserWarning: Default upsampling behavior when mode=bicubic is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
      "/Users/hansheng/Desktop/unilm/dit/venv/lib/python3.7/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    }
   ],
   "source": [
    "img, result_img, output = predict(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(\"out.jpg\", result_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instances(num_instances=8, image_height=3509, image_width=2481, fields=[pred_boxes: Boxes(tensor([[ 286.8920, 2091.7739, 2193.4136, 2320.2800],\n",
      "        [ 286.3167, 1674.0605, 2136.2017, 1845.9060],\n",
      "        [ 286.9091, 1329.9917, 2180.7046, 1441.1460],\n",
      "        [ 287.8982, 1911.1667, 2205.5776, 2023.9351],\n",
      "        [ 281.9621, 1505.9709, 2143.1118, 1609.3289],\n",
      "        [ 284.6117, 1010.8362, 1459.6604, 1084.1025],\n",
      "        [ 288.6501, 1149.3213, 1936.5421, 1263.5762],\n",
      "        [ 282.0299, 1153.4529, 1937.6528, 1201.0176]])), scores: tensor([0.9989, 0.9982, 0.9971, 0.9968, 0.9949, 0.9893, 0.9619, 0.0613]), pred_classes: tensor([0, 0, 0, 0, 0, 1, 0, 0]), pred_masks: tensor([[[False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         ...,\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False]],\n",
      "\n",
      "        [[False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         ...,\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False]],\n",
      "\n",
      "        [[False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         ...,\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         ...,\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False]],\n",
      "\n",
      "        [[False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         ...,\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False]],\n",
      "\n",
      "        [[False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         ...,\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False]]])])\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_index(instance):\n",
    "    bbox = instance.pred_boxes.tensor\n",
    "    sorting = sorted(range(bbox.size()[0]), key=lambda k: bbox[k][1].numpy())\n",
    "    return sorting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_tensor(tensor, sort_mask):\n",
    "    return tensor[sort_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort(instance):\n",
    "    sort_mask = sort_index(instance)\n",
    "    # sort pred_boxes\n",
    "    instance.pred_boxes.tensor = sort_tensor(instance.pred_boxes.tensor, sort_mask)\n",
    "    # sort score\n",
    "    instance.scores = sort_tensor(instance.scores, sort_mask)\n",
    "    # sort pred_classes\n",
    "    instance.pred_classes = sort_tensor(instance.pred_classes, sort_mask)\n",
    "    # sort pred_masks\n",
    "    instance.pred_masks = sort_tensor(instance.pred_masks, sort_mask)\n",
    "    return instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boxes(tensor([[ 284.6117, 1010.8362, 1459.6604, 1084.1025],\n",
      "        [ 288.6501, 1149.3213, 1936.5421, 1263.5762],\n",
      "        [ 282.0299, 1153.4529, 1937.6528, 1201.0176],\n",
      "        [ 286.9091, 1329.9917, 2180.7046, 1441.1460],\n",
      "        [ 281.9621, 1505.9709, 2143.1118, 1609.3289],\n",
      "        [ 286.3167, 1674.0605, 2136.2017, 1845.9060],\n",
      "        [ 287.8982, 1911.1667, 2205.5776, 2023.9351],\n",
      "        [ 286.8920, 2091.7739, 2193.4136, 2320.2800]]))\n",
      "tensor([0.9893, 0.9619, 0.0613, 0.9971, 0.9949, 0.9982, 0.9968, 0.9989])\n",
      "[1, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "output = sort(output)\n",
    "\n",
    "boxes = output.to(\"cpu\").pred_boxes if output.to(\"cpu\").has(\"pred_boxes\") else None\n",
    "scores = output.to(\"cpu\").scores if output.to(\"cpu\").has(\"scores\") else None\n",
    "classes = output.to(\"cpu\").pred_classes.tolist() if output.to(\"cpu\").has(\"pred_classes\") else None\n",
    "class_list = [\"text\",\"title\",\"list\",\"table\",\"figure\"]\n",
    "\n",
    "print(boxes)\n",
    "print(scores)\n",
    "print(classes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_remove_mask(instance, conf):\n",
    "    scores = instance.scores\n",
    "    out_mask = []\n",
    "    for idx,score in enumerate(scores):\n",
    "        if score >= conf:\n",
    "            out_mask.append(idx)\n",
    "    return out_mask\n",
    "\n",
    "def filter_tensor(tensor, mask):\n",
    "    return tensor[mask]\n",
    "\n",
    "def remove_box_lower_than(instance, conf):\n",
    "    mask = get_remove_mask(instance, conf)\n",
    "    # sort pred_boxes\n",
    "    instance.pred_boxes.tensor = filter_tensor(instance.pred_boxes.tensor, mask)\n",
    "    # sort score\n",
    "    instance.scores = filter_tensor(instance.scores, mask)\n",
    "    # sort pred_classes\n",
    "    instance.pred_classes = filter_tensor(instance.pred_classes, mask)\n",
    "    # sort pred_masks\n",
    "    instance.pred_masks = filter_tensor(instance.pred_masks, mask)\n",
    "\n",
    "    return instance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class': 'title', 'text': 'Clinical Study Synopsis for Public Disclosure\\n'}\n",
      "{'class': 'text', 'text': 'This clinical study synopsis is provided in line with Boehringer Ingelheim’s Policy on\\nTransparency and Publication of Clinical Study Data.\\n'}\n",
      "{'class': 'text', 'text': 'This clinical study synopsis is provided in line with Boehringer Ingelheim’s Policy on\\n'}\n",
      "{'class': 'text', 'text': 'The synopsis - which is part of the clinical study report - had been prepared in accordance with\\nbest practice and applicable legal and regulatory requirements at the time of study completion.\\n'}\n",
      "{'class': 'text', 'text': 'The synopsis may include approved and non-approved uses, doses, formulations, treatment regimens\\nand/or age groups; it has not necessarily been submitted to regulatory authorities.\\n'}\n",
      "{'class': 'text', 'text': 'A synopsis is not intended to provide a comprehensive analysis of all data currently available\\nregarding a particular drug. More current information regarding a drug is available in the\\napproved labeling information which may vary from country to country..\\n'}\n",
      "{'class': 'text', 'text': 'Additional information on this study and the drug concerned may be provided upon request\\nbased on Boehringer Ingelheim’s Policy on Transparency and Publication of Clinical Study Data.\\n'}\n",
      "{'class': 'text', 'text': 'The synopsis is supplied for informational purposes only in the interests of scientific disclosure.\\nIt must not be used for any commercial purposes and must not be distributed, published,\\n\\nmodified, reused, posted in any way, or used for any other purpose without the express written\\npermission of Boehringer Ingelheim.\\n'}\n"
     ]
    }
   ],
   "source": [
    "def add_padding(input_img, padding, color):\n",
    "    old_image_height, old_image_width, channels = input_img.shape\n",
    "\n",
    "    # create new image of desired size and color (blue) for padding\n",
    "    new_image_width = old_image_width + 2 * padding\n",
    "    new_image_height = old_image_height + 2 * padding\n",
    "    result = np.full((new_image_height,new_image_width, channels), color, dtype=np.uint8)\n",
    "\n",
    "    # compute center offset\n",
    "    x_center = (new_image_width - old_image_width) // 2\n",
    "    y_center = (new_image_height - old_image_height) // 2\n",
    "\n",
    "    # copy img image into center of result image\n",
    "    result[y_center:y_center+old_image_height,\n",
    "           x_center:x_center+old_image_width] = input_img\n",
    "    return result\n",
    "\n",
    "def ocr(img_cv, idx):\n",
    "    img_rgb = cv2.cvtColor(img_cv, cv2.COLOR_BGR2RGB)\n",
    "    print({\n",
    "        \"class\": class_list[classes[idx]],\n",
    "        \"text\": pytesseract.image_to_string(img_rgb)\n",
    "    })\n",
    "\n",
    "def crop_and_save_image(idx, input_img, bbox, filename, padding=25, color=(255,255,255)):\n",
    "    height, width, channels = input_img.shape\n",
    "    x1 = int(bbox[0])\n",
    "    x2 = int(bbox[2])\n",
    "    y1 = int(bbox[1])\n",
    "    y2 = int(bbox[3])\n",
    "    cropped_image = input_img[y1:y2, x1:x2]\n",
    "    padded_image = add_padding(cropped_image, padding, color)\n",
    "    ocr(padded_image, idx)\n",
    "    cv2.imwrite(filename, padded_image)\n",
    "\n",
    "out_folder = \"out\"\n",
    "try:\n",
    "    os.mkdir(out_folder)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "img = cv2.imread(image)\n",
    "\n",
    "remove_box_lower_than(output, 0.4)\n",
    "for idx, box in enumerate(boxes):\n",
    "    crop_and_save_image(idx, img, box, os.path.join(out_folder, str(idx) + \".jpg\"), 25)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}